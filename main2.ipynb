{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/ultralytics/yolov5\n",
    "# %cd yolov5\n",
    "# !pip install -qr requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "# thư viện có hàm glob để tìm các thư mục,tệp dựa trên mẫu khớp\n",
    "import glob \n",
    "from datetime import datetime\n",
    "# thư viện này cung cấp các chức năng đọc viết các tệp xml\n",
    "import xml.etree.ElementTree as ET \n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = '/kaggle/input/face-mask-detection'\n",
    "output_data = '/kaggle/working'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_path = \"/kaggle/input/face-mask-detection/annotations\"\n",
    "images_path = \"/kaggle/input/face-mask-detection/images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {\n",
    "            \"file\":[],\n",
    "            \"name\":[],    \n",
    "            \"width\":[],\n",
    "            \"height\":[],\n",
    "            \"xmin\":[],\n",
    "            \"ymin\":[],   \n",
    "            \"xmax\":[],\n",
    "            \"ymax\":[],\n",
    "           }\n",
    "\n",
    "for anno in glob.glob(annotations_path+\"/*.xml\"):\n",
    "    # đọc tệp xml\n",
    "    tree = ET.parse(anno)\n",
    "    # duyệt từng phần tử trong tree\n",
    "    for elem in tree.iter():\n",
    "        if 'size' in elem.tag:\n",
    "            # duyệt từng phần tử trong elem size\n",
    "            for attr in list(elem):\n",
    "                # lấy kích thước nhãn\n",
    "                if 'width' in attr.tag: \n",
    "                    width = int(round(float(attr.text)))\n",
    "                if 'height' in attr.tag:\n",
    "                    height = int(round(float(attr.text)))    \n",
    "\n",
    "        if 'object' in elem.tag:\n",
    "            # duyệt từng phần tử trong elem object\n",
    "            for attr in list(elem):\n",
    "                \n",
    "                if 'name' in attr.tag:\n",
    "                    name = attr.text                 \n",
    "                    dataset['name']+=[name]\n",
    "                    dataset['width']+=[width]\n",
    "                    dataset['height']+=[height] \n",
    "                    # lấy 3 phần tử cuối\n",
    "                    dataset['file']+=[anno.split('/')[-1][0:-4]] \n",
    "                            \n",
    "                if 'bndbox' in attr.tag:\n",
    "                    for dim in list(attr):\n",
    "                        if 'xmin' in dim.tag:\n",
    "                            xmin = int(round(float(dim.text)))\n",
    "                            dataset['xmin']+=[xmin]\n",
    "                        if 'ymin' in dim.tag:\n",
    "                            ymin = int(round(float(dim.text)))\n",
    "                            dataset['ymin']+=[ymin]                                \n",
    "                        if 'xmax' in dim.tag:\n",
    "                            xmax = int(round(float(dim.text)))\n",
    "                            dataset['xmax']+=[xmax]                                \n",
    "                        if 'ymax' in dim.tag:\n",
    "                            ymax = int(round(float(dim.text)))\n",
    "                            dataset['ymax']+=[ymax]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>name</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [file, name, width, height, xmin, ymin, xmax, ymax]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame(dataset)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# đặt lại tên thuư mục\n",
    "name_dict = {\n",
    "    'with_mask': 0,\n",
    "    'mask_weared_incorrect': 1,\n",
    "    'without_mask': 2 \n",
    "}\n",
    "\n",
    "df['class'] = df['name'].map(name_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(df.name.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 853 images in the dataset\n"
     ]
    }
   ],
   "source": [
    "fileNames = [*os.listdir(\"./kaggle/input/face-mask-detection/images\")]\n",
    "print('There are {} images in the dataset'.format(len(fileNames)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Train = 767\n",
      "==============================\n",
      "Length of Valid = 61\n",
      "==============================\n",
      "Length of test = 25\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(fileNames, test_size=0.1, random_state=22)\n",
    "test, val = train_test_split(test, test_size=0.7, random_state=22)\n",
    "print(\"Length of Train =\",len(train))\n",
    "print(\"=\"*30)\n",
    "print(\"Length of Valid =\",len(val))\n",
    "print(\"=\"*30)\n",
    "print(\"Length of test =\", len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: './yolov5/data/train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# os.chdir('/kaggle/working')\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./yolov5/data/train\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m os\u001b[38;5;241m.\u001b[39mmkdir(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./yolov5/data/val\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m os\u001b[38;5;241m.\u001b[39mmkdir(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./yolov5/data/test\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: './yolov5/data/train'"
     ]
    }
   ],
   "source": [
    "# os.chdir('/kaggle/working')\n",
    "# os.mkdir('./yolov5/data/train')\n",
    "# os.mkdir('./yolov5/data/val')\n",
    "# os.mkdir('./yolov5/data/test')\n",
    "# os.mkdir('./yolov5/data/train/images')\n",
    "# os.mkdir('./yolov5/data/train/labels')\n",
    "# os.mkdir('./yolov5/data/test/images')\n",
    "# os.mkdir('./yolov5/data/test/labels')\n",
    "# os.mkdir('./yolov5/data/val/images')\n",
    "# os.mkdir('./yolov5/data/val/labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def copyImages(imageList, folder_Name):\n",
    "    for image in imageList:\n",
    "        img = Image.open(input_data+\"/images/\"+image)\n",
    "        img1 = img.resize((640, 480))\n",
    "        _ = img1.save(output_data+\"/yolov5/data/\"+folder_Name+\"/images/\"+image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/kaggle/input/face-mask-detection/images/maksssksksss209.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcopyImages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m copyImages(val, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m copyImages(test, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[31], line 5\u001b[0m, in \u001b[0;36mcopyImages\u001b[1;34m(imageList, folder_Name)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcopyImages\u001b[39m(imageList, folder_Name):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m imageList:\n\u001b[1;32m----> 5\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/images/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m         img1 \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mresize((\u001b[38;5;241m640\u001b[39m, \u001b[38;5;241m480\u001b[39m))\n\u001b[0;32m      7\u001b[0m         _ \u001b[38;5;241m=\u001b[39m img1\u001b[38;5;241m.\u001b[39msave(output_data\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/yolov5/data/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mfolder_Name\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/images/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mimage)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\PIL\\Image.py:3218\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3215\u001b[0m     filename \u001b[38;5;241m=\u001b[39m fp\n\u001b[0;32m   3217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[1;32m-> 3218\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3219\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   3221\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/face-mask-detection/images/maksssksksss209.png'"
     ]
    }
   ],
   "source": [
    "copyImages(train, \"train\")\n",
    "copyImages(val, \"val\")\n",
    "copyImages(test, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['xmax'] = (640/df['width'])*df['xmax']\n",
    "df['ymax'] = (480/df['height'])*df['ymax']\n",
    "df['xmin'] = (640/df['width'])*df['xmin']\n",
    "df['ymin'] = (480/df['height'])*df['ymin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['xmax', 'ymax', 'xmin', 'ymin']] = df[['xmax', 'ymax', 'xmin', 'ymin']].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['x_center'] = (df['xmax']+df['xmin'])/(2*640)\n",
    "df['y_center'] = (df['ymax']+df['ymin'])/(2*480)\n",
    "df['box_height'] = (df['xmax']-df['xmin'])/(640)\n",
    "df['box_width'] = (df['ymax']-df['ymin'])/(480)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_labels(image_list, data_name):\n",
    "    fileNames = [x.split(\".\")[0] for x in image_list]\n",
    "\n",
    "    for name in fileNames:\n",
    "        data = df[df.file==name]\n",
    "        box_list = []\n",
    "        \n",
    "        for index in range(len(data)):\n",
    "            row = data.iloc[index]\n",
    "            box_list.append(row['class']+\" \"+row[\"x_center\"]+\" \"+row[\"y_center\"]\\\n",
    "                        +\" \"+row[\"box_height\"]+\" \"+row[\"box_width\"])\n",
    "            \n",
    "        text = \"\\n\".join(box_list)\n",
    "        with open(output_data+\"/yolov5/data/\"+data_name+\"/labels/\"+name+\".txt\", \"w\") as file:\n",
    "            file.write(text)\n",
    "\n",
    "\n",
    "create_labels(train, \"train\")\n",
    "create_labels(val, \"val\")\n",
    "create_labels(test, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, clear_output\n",
    "import torch\n",
    "from yolov5 import utils\n",
    "display = utils.notebook_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure .yaml file to guide the model for training\n",
    "yaml_text = \"\"\"train: data/train/images\n",
    "val: data/train/images\n",
    "\n",
    "nc: 3\n",
    "names: ['with_mask', 'mask_weared_incorrect', 'without_mask']\"\"\"\n",
    "\n",
    "with open(\"data/data.yaml\", 'w') as file:\n",
    "    file.write(yaml_text)\n",
    "\n",
    "%cat data/data.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#customize iPython writefile so we can write variables\n",
    "from IPython.core.magic import register_line_cell_magic\n",
    "\n",
    "@register_line_cell_magic\n",
    "def writetemplate(line, cell):\n",
    "    with open(line, 'w') as f:\n",
    "        f.write(cell.format(**globals()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writetemplate models/custom_yolov5s.yaml\n",
    "\n",
    "# parameters\n",
    "nc: 3  # number of classes\n",
    "depth_multiple: 0.33  # model depth multiple\n",
    "width_multiple: 0.50  # layer channel multiple\n",
    "\n",
    "# anchors\n",
    "anchors:\n",
    "    - [10,13, 16,30, 33,23]  # P3/8\n",
    "    - [30,61, 62,45, 59,119]  # P4/16\n",
    "    - [116,90, 156,198, 373,326]  # P5/32\n",
    "\n",
    "# YOLOv5 backbone\n",
    "backbone:\n",
    "  # [from, number, module, args]\n",
    "  [[-1, 1, Focus, [64, 3]],  # 0-P1/2\n",
    "   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n",
    "   [-1, 3, BottleneckCSP, [128]],\n",
    "   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n",
    "   [-1, 9, BottleneckCSP, [256]],\n",
    "   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n",
    "   [-1, 9, BottleneckCSP, [512]],\n",
    "   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n",
    "   [-1, 1, SPP, [1024, [5, 9, 13]]],\n",
    "   [-1, 3, BottleneckCSP, [1024, False]],  # 9\n",
    "  ]\n",
    "\n",
    "# YOLOv5 head\n",
    "head:\n",
    "    [[-1, 1, Conv, [512, 1, 1]],\n",
    "    [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
    "    [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n",
    "    [-1, 3, BottleneckCSP, [512, False]],  # 13\n",
    "\n",
    "    [-1, 1, Conv, [256, 1, 1]],\n",
    "    [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
    "    [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n",
    "    [-1, 3, BottleneckCSP, [256, False]],  # 17 (P3/8-small)\n",
    "\n",
    "    [-1, 1, Conv, [256, 3, 2]],\n",
    "    [[-1, 14], 1, Concat, [1]],  # cat head P4\n",
    "    [-1, 3, BottleneckCSP, [512, False]],  # 20 (P4/16-medium)\n",
    "\n",
    "    [-1, 1, Conv, [512, 3, 2]],\n",
    "    [[-1, 10], 1, Concat, [1]],  # cat head P5\n",
    "    [-1, 3, BottleneckCSP, [1024, False]],  # 23 (P5/32-large)\n",
    "\n",
    "    [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train yolov5s on custom data for 100 epochs\n",
    "# time its performance\n",
    "# we are going to using pre-trained weights from yolov5.pt model\n",
    "\n",
    "start = datetime.now()\n",
    "!python train.py --img 640 --batch 32 --epochs 50 --data data/data.yaml --cfg models/custom_yolov5s.yaml --weights yolov5s.pt --name yolov5s_results  --cache\n",
    "end = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Runtime =\",end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets visualize the training results\n",
    "img = plt.imread('runs/train/yolov5s_results/train_batch0.jpg')\n",
    "plt.figure(figsize=(20,15))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python detect.py --source data/test/images/ --weight runs/train/yolov5s_results/weights/best.pt --name expTestImage --conf 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_dict = {\n",
    "    'with_mask': (0, 255, 0),\n",
    "    'mask_weared_incorrect':  (0, 0, 255),\n",
    "    'without_mask': (255, 0, 0) \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(img_id):\n",
    "    df_image = df[df.file==img_id]\n",
    "    df_image[['xmin', 'ymin', 'xmax', 'ymax']] = df_image[['xmin', 'ymin', 'xmax', 'ymax']].astype('int64')\n",
    "    path = 'data/test/images/'+img_id# +'.png'\n",
    "    img = plt.imread(path)\n",
    "\n",
    "    imge = img.copy()\n",
    "\n",
    "    for index in range(len(df_image)):\n",
    "        row = df_image.iloc[index]\n",
    "        cv2.rectangle(imge, \n",
    "                      (row['xmin'], row['ymin']),\n",
    "                      (row['xmax'], row['ymax']),\n",
    "                      color=color_dict[row['name']],\n",
    "                      thickness=2)\n",
    "\n",
    "    img_pred = plt.imread('runs/detect/expTestImage/'+img_id)\n",
    "    # ===================================\n",
    "    plt.figure(figsize=(14,17))\n",
    "\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(imge)\n",
    "    plt.axis('off')\n",
    "    plt.title('Image with Truth Box')\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(img_pred)\n",
    "    plt.axis('off')\n",
    "    plt.title('Image with Predicted Box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random\n",
    "show_image(random.choice(os.listdir(\"data/test/images/\"))) \n",
    "show_image(random.choice(os.listdir(\"data/test/images/\"))) \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
