{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Could not find directory ./dataset/train",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_data \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_dataset_from_directory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./dataset/train\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minferred\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcategorical\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m      8\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# train_data = train_data.map(lambda x, y: (tf.image.resize(x, [128, 128]), y)).shuffle(1024)\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\utils\\image_dataset.py:213\u001b[0m, in \u001b[0;36mimage_dataset_from_directory\u001b[1;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, **kwargs)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m seed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    212\u001b[0m     seed \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m1e6\u001b[39m)\n\u001b[1;32m--> 213\u001b[0m image_paths, labels, class_names \u001b[38;5;241m=\u001b[39m \u001b[43mdataset_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_directory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    216\u001b[0m \u001b[43m    \u001b[49m\u001b[43mformats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mALLOWLIST_FORMATS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_links\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_links\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m label_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(class_names) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWhen passing `label_mode=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`, there must be exactly 2 \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    226\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass_names. Received: class_names=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_names\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    227\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\utils\\dataset_utils.py:542\u001b[0m, in \u001b[0;36mindex_directory\u001b[1;34m(directory, labels, formats, class_names, shuffle, seed, follow_links)\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    541\u001b[0m     subdirs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 542\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m subdir \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[0;32m    543\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39misdir(tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mjoin(directory, subdir)):\n\u001b[0;32m    544\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m subdir\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py:768\u001b[0m, in \u001b[0;36mlist_directory_v2\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    753\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns a list of entries contained within a directory.\u001b[39;00m\n\u001b[0;32m    754\u001b[0m \n\u001b[0;32m    755\u001b[0m \u001b[38;5;124;03mThe list is in arbitrary order. It does not contain the special entries \".\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    765\u001b[0m \u001b[38;5;124;03m  errors.NotFoundError if directory doesn't exist\u001b[39;00m\n\u001b[0;32m    766\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    767\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_directory(path):\n\u001b[1;32m--> 768\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mNotFoundError(\n\u001b[0;32m    769\u001b[0m       node_def\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    770\u001b[0m       op\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    771\u001b[0m       message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find directory \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(path))\n\u001b[0;32m    773\u001b[0m \u001b[38;5;66;03m# Convert each element to string, since the return values of the\u001b[39;00m\n\u001b[0;32m    774\u001b[0m \u001b[38;5;66;03m# vector of string should be interpreted as strings, not bytes.\u001b[39;00m\n\u001b[0;32m    775\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m    776\u001b[0m     compat\u001b[38;5;241m.\u001b[39mas_str_any(filename)\n\u001b[0;32m    777\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m _pywrap_file_io\u001b[38;5;241m.\u001b[39mGetChildren(compat\u001b[38;5;241m.\u001b[39mpath_to_bytes(path))\n\u001b[0;32m    778\u001b[0m ]\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Could not find directory ./dataset/train"
     ]
    }
   ],
   "source": [
    "train_data = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory='./dataset/train',\n",
    "    labels=\"inferred\",\n",
    "    image_size = (224, 224),\n",
    "    label_mode='categorical',\n",
    "    batch_size=16,\n",
    "    shuffle=True\n",
    ")\n",
    "# train_data = train_data.map(lambda x, y: (tf.image.resize(x, [128, 128]), y)).shuffle(1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TabError",
     "evalue": "inconsistent use of tabs and spaces in indentation (2941098475.py, line 19)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[16], line 19\u001b[1;36m\u001b[0m\n\u001b[1;33m    data = np.reshape(image ,[224,224,3])/255.0\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mTabError\u001b[0m\u001b[1;31m:\u001b[0m inconsistent use of tabs and spaces in indentation\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "\n",
    "DIRECTORY = \"./dataset\"\n",
    "CATEGORIES = [\"with_mask\", \"without_mask\", \"mask_weared_incorrect\"]\n",
    "######################################################################\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for category in CATEGORIES:\n",
    "    path = os.path.join(DIRECTORY, category)\n",
    "    for img in os.listdir(path):\n",
    "    \timg_path = os.path.join(path, img)\n",
    "        \n",
    "    \timage = load_img(img_path, target_size=(224, 224))\n",
    "    \timage = img_to_array(image)\n",
    "        data = np.reshape(image ,[224,224,3])/255.0\n",
    "\n",
    "    \tdata.append(image)\n",
    "    \tlabels.append(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 1833581568 into shape (224,224,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255.0\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\core\\fromnumeric.py:285\u001b[0m, in \u001b[0;36mreshape\u001b[1;34m(a, newshape, order)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_reshape_dispatcher)\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreshape\u001b[39m(a, newshape, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    202\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;124;03m    Gives a new shape to an array without changing its data.\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;124;03m           [5, 6]])\u001b[39;00m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreshape\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\core\\fromnumeric.py:56\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     54\u001b[0m bound \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, method, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bound \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bound(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\core\\fromnumeric.py:45\u001b[0m, in \u001b[0;36m_wrapit\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m     44\u001b[0m     wrap \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wrap:\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, mu\u001b[38;5;241m.\u001b[39mndarray):\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 1833581568 into shape (224,224,3)"
     ]
    }
   ],
   "source": [
    "data = np.reshape(data ,[224,224,3])/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# phân chia dữ liệu train:test(80:20), test:val(70:30)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_with_mask, test_with_mask = train_test_split(with_mask, test_size=0.20, random_state=42)\n",
    "test_with_mask, val_with_mask = train_test_split(test_with_mask, test_size=0.7, random_state=42)\n",
    "\n",
    "train_mask_weared_incorrect, test_mask_weared_incorrect = train_test_split(mask_weared_incorrect, test_size=0.20, random_state=42)\n",
    "test_mask_weared_incorrect, val_mask_weared_incorrect = train_test_split(test_mask_weared_incorrect, test_size=0.7, random_state=42)\n",
    "\n",
    "train_without_mask, test_without_mask = train_test_split(without_mask, test_size=0.20, random_state=42)\n",
    "test_without_mask, val_without_mask = train_test_split(test_without_mask, test_size=0.7, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory='./dataset/test',\n",
    "    labels=\"inferred\",\n",
    "    image_size = (224, 224),\n",
    "    label_mode='categorical',\n",
    "    batch_size=16,\n",
    "    shuffle=True\n",
    ")\n",
    "# test_data = test_data.map(lambda x, y: (tf.image.resize(x, [128, 128]), y)).shuffle(1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory='./dataset/val',\n",
    "    labels=\"inferred\",\n",
    "    image_size = (224, 224),\n",
    "    label_mode='categorical',\n",
    "    batch_size=16,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "val_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255\n",
    ")\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255, #chuẩn hóa (0,1)\n",
    "    horizontal_flip=True, #lật theo chiều dọc\n",
    "    zoom_range=0.1, #phóng to 10%\n",
    "    shear_range=0.2, # làm méo ảnh\n",
    "    width_shift_range=0.1, #dịch chuyển ngang 10%\n",
    "    height_shift_range=0.1, #dịch chuyển dọc 10%\n",
    "    rotation_range=4, #xoay 4 độ\n",
    "    vertical_flip=False \n",
    "\n",
    ")\n",
    " \n",
    "# train data\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    directory='./kaggle/working/train', \n",
    "    target_size = (224,224),\n",
    "    class_mode=\"categorical\",\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    "\n",
    ")\n",
    "\n",
    "# Validation data\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    directory='./kaggle/working/val', \n",
    "    target_size = (224,224),\n",
    "    class_mode=\"categorical\", \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Test data\n",
    "test_generator = val_datagen.flow_from_directory(\n",
    "    directory='./kaggle/working/test', \n",
    "    target_size = (224,224),\n",
    "    class_mode=\"categorical\", \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "model_custom = Sequential()\n",
    "model_custom.add(Conv2D(filters = 16, kernel_size = 3,  padding='same', activation = 'relu', input_shape = (224,224,3)))\n",
    "model_custom.add(MaxPooling2D(pool_size = 2))\n",
    "model_custom.add(Conv2D(filters = 32, kernel_size = 3,  padding='same', activation = 'relu'))\n",
    "model_custom.add(MaxPooling2D(pool_size = 2))\n",
    "model_custom.add(Conv2D(filters = 64, kernel_size = 3,  padding='same', activation = 'relu'))\n",
    "model_custom.add(MaxPooling2D(pool_size = 2))\n",
    "model_custom.add(Dropout(0.3))\n",
    "model_custom.add(Flatten())\n",
    "model_custom.add(Dense(units = 500, activation = 'relu'))\n",
    "model_custom.add(Dropout(0.3))\n",
    "model_custom.add(Dense(units = 3, activation = 'softmax'))\n",
    "\n",
    "\n",
    "model_custom.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = len(train_data) \n",
    "#data_size2 = train_generator.n\n",
    "\n",
    "#print(f\"data_size: {data_size}, {data_size2}\")\n",
    "\n",
    "steps_per_epoch = int(data_size / batch_size)\n",
    "print(f\"steps_per_epoch: {steps_per_epoch}\")\n",
    "\n",
    "val_steps = int(len(val_data) // batch_size)\n",
    "#print(f\"val size: {len(val_generator)}\")\n",
    "print(f\"val_steps: {val_steps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "import tensorflow as tf\n",
    "model_custom.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss= tf.keras.losses.CategoricalFocalCrossentropy(\n",
    "        gamma=1.5,\n",
    "        name='categorical_focal_crossentropy'\n",
    "    ),\n",
    "    metrics=['accuracy', 'Recall', 'Precision', 'AUC']\n",
    "\n",
    ")\n",
    "\n",
    "# Early Stopping\n",
    "# Before training the network, we define an early stopping criterion,\n",
    "#to avoid redundent epochs once the model has already converged.\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True)\n",
    "\n",
    "# Reduce Learning Rate On Plateau\n",
    "# We define a `ReduceLROnPlateau` callback to reduce the learning rate when the metric\n",
    "# we chose (`val_loss`) has stopped improving.\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "lrr = ReduceLROnPlateau(monitor='val_loss',patience=8,verbose=1,factor=0.5, min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_custom_history = model_custom.fit_generator(\n",
    "    generator=train_data,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=epochs,\n",
    "    shuffle=True,\n",
    "    #verbose=2,\n",
    "    validation_data=val_data,\n",
    "    validation_steps=val_steps,\n",
    "    callbacks=[lrr]\n",
    ")\n",
    "\n",
    "model_custom.save('model_custom3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model performance on test data\n",
    "model_custom_loss, model_custom_acc, custom_recall, custom_precision, custom_auc = model_custom.evaluate(test_generator)\n",
    "print(\"Our Custom Model has a loss of %.2f and accuracy %.2f%%\" % (model_custom_loss, model_custom_acc*100))\n",
    "print(\"Our Custom Model has a recall of %.2f%%, precision of %.2f%% and auc of %.2f%%\" % (custom_recall*100, custom_precision*100, custom_auc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_predictions = model_custom.predict(test_generator)\n",
    "print(\"predictions shape:\", custom_predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "paths = test_generator.filenames # mảng chứa đường dẫn của tên file test\n",
    "y_pred_custom = model_custom.predict(test_generator).argmax(axis=1) # mảng chứa dự đoán tất cả nhãn\n",
    "classes = test_generator.class_indices  # danh sách tên nhãn\n",
    "\n",
    "a_img_rand = np.random.randint(0,len(paths))   # chọn ngẫu nhiên thứ tự hình ảnh\n",
    "img = cv2.imread(os.path.join(output_data_path,'test', paths[a_img_rand]))  \n",
    "colored_img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)  # ảnh đầu ra có màu\n",
    "\n",
    "# xuất hình ảnh được chọn ngẫu nhiên\n",
    "plt.imshow(colored_img)\n",
    "# nhãn đúng\n",
    "true_label = paths[a_img_rand].split('/')[0]\n",
    "# dự đoán nhãn\n",
    "predicted_label = list(classes)[y_pred_custom[a_img_rand]]\n",
    "print(f'Class Predicted: {predicted_label} , True label: {true_label} for Custom Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = test_generator.labels\n",
    "y_pred_custom  = model_custom.predict(test_generator).argmax(axis=1) # Predict prob and get Class Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img = cv2.imread(os.path.join(input_data_path, f'{final_test_image}.png'))      \n",
    "colored_img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)  # colored output image\n",
    "\n",
    "#print(type(colored_img))\n",
    "mask_label = {0:'MASK INCORRECT',1:'MASK', 2:'NO MASK'}\n",
    "color_label = {0:(0,255,255),1:(0, 255,0), 2:(255,0,0)}\n",
    "cropped_faces = extract_faces(f'{final_test_image}.png', df_final_test)\n",
    "\n",
    "df_test_img = df_final_test[['xmin', 'ymin', 'xmax', 'ymax', 'label']]\n",
    "#for row_num in range(len(df_test_img)):\n",
    "for idx, face in enumerate(cropped_faces):    \n",
    "    # print(idx)\n",
    "    x_min, y_min, x_max, y_max, label = df_test_img.iloc[idx] \n",
    "    # print(x_min, y_min, x_max, y_max, label)\n",
    "   \n",
    "    resized_face = cv2.resize(np.array(face[0]),(224,224))\n",
    "    # chuẩn hóa\n",
    "    reshaped_face = np.reshape(resized_face,[1,224,224,3])/255.0\n",
    "    # mảng lưu trũ tỉ lệ dự đoán của từng nhãn\n",
    "    face_result = model_custom.predict(reshaped_face)\n",
    "\n",
    "    cv2.putText(colored_img,mask_label[face_result.argmax()],(x_min, y_min-10),cv2.FONT_HERSHEY_SIMPLEX,0.5,color_label[face_result.argmax()],2)\n",
    "    cv2.rectangle(colored_img,(x_min, y_min), (x_max, y_max), color_label[face_result.argmax()]) # print a blue rectangle of each person's face using the given coordinates\n",
    "\n",
    "plt.figure(figsize=(10, 10))    \n",
    "plt.imshow(colored_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
